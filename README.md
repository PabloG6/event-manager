# Dealing with Database Locks and Concurrency With Queues and Event Sourcing.

## Events

Events hold the metadata for a task. A task can be seen as a `POST` request that accepts a payload. An event can have a `referenceId`, which is separate from it's `eventId`, which is generated at creation. When an event is created, it is sent to an `EventWorker` to be queued for processing. 


### Events data
```
{
    url: `https://example.com/create-example` //,
    payload: json, //payload to be consumed by the event
    eventId: binary //generated by api, used to identify an event.
    referenceId: binary, // a unique id used to group events together.
    maxRetries: integer //maximum number of retries an event worker should attempt before moving to the next task.
    createdAt: timestamp, //generated by api, used to show when an event was created.
    completedAt: timestamp, //generated by api, used to show when an event was completed
    isCompleted: boolean //generated by api, used to show if an event is completed.
    isFailed: boolean //generated by api, used to show if an event failed.
    exceptionMessage: json || string, //the failure response of the endpoint if an event fails, 

}
```


## Event Workers
Event workers are separate processes used to manage, store and execute events. Event workers store events in a queue, and thus operate on a `FIFO` protocol.
A `queue` allows a concurrent approach to managing events. Processes that otherwise use similar resources are executed one after the other, preventing them from
causing concurrency issues such as deadlocks and working with stale data. However, running a single event worker can slow down a system considerably if several
events are queued to that worker. This is why event workers take into consideration the `referenceId` of each event. The `referenceId` can be seen as a way to group the events for a specific resource together. This means that an event worker can only manage events for a fixed number of resources. When a single `EventWorker` has reached the maximum number of references, a new event worker will be created. When an `EventWorker` is complete, it gracefully shuts down. If an `EventWorker` was previously registered as full, it will no longer accept new events and will complete all existing events until the queue is empty. This is to prevent an event worker with stale events from staying around too long. While an `EventWorker` can technically run indefinitely providing it has the free bandwidth, it is considered better to start a new `EventWorker` once a previous one is full. If the `EventService` has no running event workers, a new one is instantiated and that event is added to that event worker's  queue.

### Event Worker data

```
{
    workerId: string, //generated by api, used to identify an event worker.
    createdAt: timestamp, //generated by api, used to identify when a worker was created.
    lastCompletedTask: eventId, //generated by api, used to identify last completed task
    tasksRemaining: int, //generated by api, used to identify remaining tasks.
    willTerminate: boolean, //generated by api, used to determine if an event worker is full and will shutdown when all tasks in queue are complete.
    tasksCompleted: int, //generated by api, used to figure out completed tasks
    tasksFailed: int, //generated by api, used to figure out tasks which failed.
    maxReferenceCount: int, //used to determine the max number of resources an event worker can manage. 
    isDone: boolean, //internal use only, used to determine if the event service should create this worker.
    queue: queue, //internal use only, the events to be queued
}
```


## Event Service

The event service is an abstraction used to manage the creation, processing and graceful shutdown of event workers. The `EventService` generally accepts events, and internally decides whether or not to create a new `EventWorker` or to append the event to an existing worker. The `EventService` is also responsible for re-initializing event workers with event metadata in the event that the events application shuts down. This prevents us from losing the last known state of a system. The `EventService` does this by writing all event data to an `Events` and ` Event Worker` table. The `Events` table stores metadata on all events, and is updated synchronously on completion of each event. The `EventsService` then queries the `Event Worker` for incomplete workers and creates them. It then queries the `Events` table and associates the metadata accordingly. The `Events` table also stores a key for it's parent `Event Worker` which allows us to reinstantiate `EventWorkers` with the right data. While we can technically instantiate new event workers with data from the `Events` table, it is good to log the `Event Workers` metadata for auditing purposes.  The `Event Worker` table stores the last completed `event`, the number of completed events and the number of failed events. 


# Refactoring the system to work with the current Event Service.

